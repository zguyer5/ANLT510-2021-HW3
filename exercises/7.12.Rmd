---
output: html_document
---

## Exercise 7.12

__This problem is a continuation of the previous exercise. In a toy example with $p = 100$, show that one can approximate the multiple linear regression coefficient estimates by repeatedly performing simple linear regression in a backfitting procedure. How many backfitting iterations are required in order to obtain a “good” approximation to the multiple regression coefficient estimates? Create a plot to justify your answer.__

Step 1: give $\hat \beta_1, \dots, \hat \beta_{99}$ arbitrary initial values.

Step 2: fit the model:
$$
Y - \hat\beta_1 X_1 - \dots - \hat\beta_{99} X_{99} = \beta_0 + \beta_{100} X_{100} + \epsilon
$$
So we have the values of $\hat \beta_0$ and $\hat \beta_{100}$.

Step 3: with this new $\hat\beta_{100}$, fit the model:
$$
Y - \hat\beta_1 X_1 - \dots - \hat\beta_{98} X_{98} - \hat\beta_{100}X_{100} = \beta_0 + \beta_{99} X_{99} + \epsilon
$$

Repeat above step until fitting the model:
$$
Y - \hat\beta_2 X_2 - \dots - \hat\beta_{100}X_{100} = \beta_0 + \beta_{1} X_{1} + \epsilon
$$

So we have new values of $\hat \beta_0$ and $\hat \beta_1$.
With this $\hat \beta_1$ fit the model in step 2 again.

Repeat this loop until $\hat\beta_0, \dots, \hat\beta_{100}$ converge.
